{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ray import tune\n",
    "from ray.train import Checkpoint, get_checkpoint\n",
    "import ray.cloudpickle as pickle\n",
    "\n",
    "from data_prep import clean_data, dataset\n",
    "from data_prep.utils import shuffle_by_timestep, shuffle_non_padded, masked_mae, compute_iou\n",
    "from models import transformer\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\outcome_modeling\\data_prep\\clean_data.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['COURSE'] = df['SUBJECT'] + ' ' + df['COURSE_NUMBER']\n"
     ]
    }
   ],
   "source": [
    "df = clean_data.load_data()\n",
    "df = clean_data.clean_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mappings used to identify courses from ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_id_map, id_course_map = clean_data.course_id_maps(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_id_map, id_major_map = clean_data.major_id_maps(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = course_id_map[\"<PAD>\"]\n",
    "SOS_IDX = course_id_map[\"<SOS>\"]\n",
    "EOS_IDX = course_id_map[\"<EOS>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_seqs, student_tensors, semester_tensors, major_tensors, grade_tensors = dataset.course_semester_tensors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5326 students, 360 courses, 48 majors, 18 \"semesters\"\n"
     ]
    }
   ],
   "source": [
    "n_students = len(student_seqs)\n",
    "n_courses = len(course_id_map)\n",
    "n_semesters = df['SEMESTER_RANK'].nunique()\n",
    "n_majors = len(major_id_map) \n",
    "\n",
    "print(f'{n_students} students, {n_courses} courses, {n_majors} majors, {n_semesters} \"semesters\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min courses: 7, Max courses: 58\n"
     ]
    }
   ],
   "source": [
    "student_tensor_sizes = [x.size()[0] for x in student_tensors]\n",
    "print(f'Min courses: {min(student_tensor_sizes)}, Max courses: {max(student_tensor_sizes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader = dataset.course_seq_dataloader(student_tensors, semester_tensors, major_tensors, grade_tensors, n_courses, SOS_IDX, EOS_IDX, PAD_IDX, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab a single batch for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, X_pos, y, y_pos, majors, input_grades, target_grades in train_dataloader:\n",
    "    assert X.size() == X_pos.size()\n",
    "    assert y.size() == y_pos.size()\n",
    "    assert input_grades.size() == X.size()\n",
    "    assert target_grades.size() == y.size()\n",
    "\n",
    "    # Place on device\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    X_pos = X_pos.to(device)\n",
    "    y_pos = y_pos.to(device)\n",
    "    majors = majors.to(device)\n",
    "    input_grades = input_grades.to(device)\n",
    "    target_grades = target_grades.to(device)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_courses=X\n",
    "tgt_courses=y \n",
    "src_gpas=input_grades\n",
    "tgt_gpas=target_grades\n",
    "src_courses_positions=X_pos\n",
    "tgt_courses_positions=y_pos\n",
    "major=majors\n",
    "memory_key_padding_mask=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "major: torch.Size([32])\n",
      "src_courses: torch.Size([32, 56])\n",
      "src_gpas: torch.Size([32, 56])\n",
      "src_courses_positions: torch.Size([32, 56])\n",
      "tgt_courses: torch.Size([32, 12])\n",
      "tgt_gpas: torch.Size([32, 12])\n",
      "tgt_courses_positions: torch.Size([32, 12])\n"
     ]
    }
   ],
   "source": [
    "print(f'major: {major.size()}')\n",
    "\n",
    "print(f'src_courses: {src_courses.size()}')\n",
    "print(f'src_gpas: {src_gpas.size()}')\n",
    "print(f'src_courses_positions: {src_courses_positions.size()}')\n",
    "\n",
    "print(f'tgt_courses: {tgt_courses.size()}')\n",
    "print(f'tgt_gpas: {tgt_gpas.size()}')\n",
    "print(f'tgt_courses_positions: {tgt_courses_positions.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "major: 6\n",
      "\n",
      "src_courses:\n",
      " tensor([358,  13,  17,  32,  44,  50,  72,  96, 359,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       device='cuda:0')\n",
      "\n",
      "src_gpas:\n",
      " tensor([0.0000, 0.9302, 1.0000, 0.9302, 0.9302, 0.9302, 0.6977, 0.4651, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000], device='cuda:0')\n",
      "\n",
      "src_courses_positions:\n",
      " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "tgt_courses:\n",
      " tensor([358,  28,  46,  51,  73, 111, 130, 359,   0,   0,   0,   0],\n",
      "       device='cuda:0')\n",
      "\n",
      "tgt_gpas:\n",
      " tensor([0.0000, 0.8605, 0.5349, 0.4651, 0.6977, 0.7674, 0.8605, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000], device='cuda:0')\n",
      "\n",
      "tgt_courses_positions:\n",
      " tensor([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'major: {major[0]}\\n')\n",
    "\n",
    "print(f'src_courses:\\n {src_courses[0]}\\n')\n",
    "print(f'src_gpas:\\n {src_gpas[0]}\\n')\n",
    "print(f'src_courses_positions:\\n {src_courses_positions[0]}\\n')\n",
    "\n",
    "print(f'tgt_courses:\\n {tgt_courses[0]}\\n')\n",
    "print(f'tgt_gpas:\\n {tgt_gpas[0]}\\n')\n",
    "print(f'tgt_courses_positions:\\n {tgt_courses_positions[0]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_courses:\n",
      " ['<SOS>', 'BIOL 1107', '<OTHER>', 'WRIT 1301', 'SPAN 1312', 'FYSM 1100', 'BIOL 1307', 'MATH 2312', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "tgt_courses:\n",
      " ['<SOS>', 'COMM 1317', 'MATH 2413', 'BIOL 1308', 'BIOL 1108', 'GLST 1322', 'RELS 2342', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "\n",
      "major: Biology\n",
      "\n",
      "src_courses_positions:\n",
      " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "tgt_courses_positions:\n",
      " tensor([2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'src_courses:\\n {[id_course_map[x.item()] for x in src_courses[0]]}\\n')\n",
    "print(f'tgt_courses:\\n {[id_course_map[x.item()] for x in tgt_courses[0]]}\\n')\n",
    "print(f'major: {id_major_map[major[0].item()]}\\n')\n",
    "print(f'src_courses_positions:\\n {src_courses_positions[0]}\\n')\n",
    "print(f'tgt_courses_positions:\\n {tgt_courses_positions[0]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate padding masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_key_padding_mask = dataset.generate_src_padding_masks(src_courses, major, PAD_IDX).to(device)\n",
    "tgt_key_padding_mask = dataset.generate_tgt_padding_masks(tgt_courses, PAD_IDX).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 + src_courses.size(1) + src_gpas.size(1) == src_key_padding_mask.size(1), \"Padding mask size doesn't match src size\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually inspect padding masks. `False` is _not_ padding, `True` _is_ padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(False, device='cuda:0'), tensor(2, device='cuda:0'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_key_padding_mask[0, 0], major[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        device='cuda:0'),\n",
       " tensor([358, 359,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0], device='cuda:0'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_key_padding_mask[0, 1:src_courses.size(1)], src_courses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        device='cuda:0'),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_key_padding_mask[0, 1+src_courses.size(1):2*src_courses.size(1)], src_gpas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False, False, False, False, False, False, False,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        device='cuda:0'),\n",
       " tensor([358,  28,  29,  34,  58, 201, 359,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_key_padding_mask[0, :tgt_courses.size(1)], tgt_courses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([False, False, False, False, False, False,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        device='cuda:0'),\n",
       " tensor([0.0000, 0.6977, 0.9302, 0.4651, 0.0000, 0.6279, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000], device='cuda:0'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_key_padding_mask[0, 1+tgt_courses.size(1):], tgt_gpas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate source mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one for the major\n",
    "src_seq_len = 1 + src_courses.size(1) + src_gpas.size(1)\n",
    "tgt_courses_seq_len = tgt_courses.size(1)\n",
    "\n",
    "src_mask = dataset.generate_src_mask(src_seq_len).to(device)\n",
    "tgt_mask = dataset.generate_tgt_mask(tgt_courses_seq_len).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_seq_len, tgt_courses_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([123, 123]), torch.Size([40, 40]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_mask.size(), tgt_mask.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ~src_mask.all(), \"All elements of src_mask should be False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "config['d_model'] = 128\n",
    "config['nhead'] = 8\n",
    "config['num_encoder_layers'] = 4\n",
    "config['num_decoder_layers'] = 4\n",
    "config['dim_feedforward'] = 512\n",
    "config['major_embedding_dim'] = 16\n",
    "config['course_embedding_dim'] = 100\n",
    "config['gpa_embedding_dim'] = 16\n",
    "config['dropout'] = 0.1\n",
    "config['lr'] = 1e-4\n",
    "config['weight_decay'] = 0.1\n",
    "\n",
    "model = transformer.TransformerModelWithGrades(n_courses=n_courses,\n",
    "                                               n_majors=n_majors,\n",
    "                                               max_len=100,\n",
    "                                               config=config,\n",
    "                                               PAD_IDX=PAD_IDX).to(device)\n",
    "\n",
    "model = nn.DataParallel(model, device_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:5109: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n",
      "c:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Shift target to the right\n",
    "# Input targets to the decoder ignore the last element\n",
    "# Prediction targets ignore the first element\n",
    "tgt_courses_input = tgt_courses.detach().clone()\n",
    "tgt_grades_input = target_grades.detach().clone()\n",
    "tgt_pos_input = tgt_courses_positions.detach().clone()\n",
    "\n",
    "# Find index of EOS_IDX in tgt_courses\n",
    "eos_tgt_loc = (tgt_courses_input == EOS_IDX).nonzero()\n",
    "tgt_courses_input[eos_tgt_loc[:, 0], eos_tgt_loc[:, 1]] = PAD_IDX\n",
    "tgt_grades_input[eos_tgt_loc[:, 0], eos_tgt_loc[:, 1]] = 0.\n",
    "tgt_pos_input[eos_tgt_loc[:, 0], eos_tgt_loc[:, 1]] = 0\n",
    "\n",
    "# Now trim off the last element\n",
    "tgt_courses_input = tgt_courses_input[:, :-1]\n",
    "tgt_grades_input = tgt_grades_input[:, :-1]\n",
    "tgt_pos_input = tgt_pos_input[:, :-1]\n",
    "\n",
    "tgt_out = tgt_courses[:, 1:]\n",
    "tgt_grades_out = target_grades[:, 1:]\n",
    "tgt_pos_out = tgt_courses_positions[:, 1:]\n",
    "\n",
    "# Source and target masks\n",
    "# Add one for the major\n",
    "# src_seq_len = 1 + src_courses.size(1) + src_gpas.size(1)\n",
    "# tgt_input_courses_seq_len = tgt_grades_input.size(1)\n",
    "\n",
    "# src_mask = dataset.generate_src_mask(src_seq_len).to(device)\n",
    "# tgt_input_mask = dataset.generate_tgt_mask(tgt_input_courses_seq_len).to(device)\n",
    "\n",
    "# # Padding masks\n",
    "# src_key_padding_mask = dataset.generate_src_padding_masks(src_courses, majors, PAD_IDX).to(device)\n",
    "# tgt_key_padding_input_mask = dataset.generate_tgt_padding_masks(tgt_courses_input, PAD_IDX).to(device)\n",
    "\n",
    "# Place on device\n",
    "majors = majors.to(device)\n",
    "src_courses = src_courses.to(device)\n",
    "tgt_courses_input = tgt_courses_input.to(device)\n",
    "src_gpas = src_gpas.to(device)\n",
    "tgt_grades_input = tgt_grades_input.to(device)\n",
    "src_courses_positions = src_courses_positions.to(device)\n",
    "tgt_pos_input = tgt_pos_input.to(device)\n",
    "# src_key_padding_mask = src_key_padding_mask.to(device)\n",
    "\n",
    "# Forward pass\n",
    "output_courses_lsm, output_gpas, output_courses = model(major=majors,\n",
    "                                                        src_courses=src_courses, \n",
    "                                                        tgt_courses=tgt_courses_input, \n",
    "                                                        src_gpas=src_gpas, \n",
    "                                                        tgt_gpas=tgt_grades_input, \n",
    "                                                        src_courses_positions=src_courses_positions, \n",
    "                                                        tgt_courses_positions=tgt_pos_input,\n",
    "                                                        # src_mask=src_mask,\n",
    "                                                        # tgt_mask=tgt_input_mask,\n",
    "                                                        # src_key_padding_mask=src_key_padding_mask,\n",
    "                                                        # tgt_key_padding_mask=tgt_key_padding_input_mask,\n",
    "                                                        # memory_key_padding_mask=src_key_padding_mask)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_courses: torch.Size([32, 360, 11])\n",
      "output_gpas: torch.Size([32, 11, 1])\n",
      "output_courses_lsm: torch.Size([32, 360, 11])\n"
     ]
    }
   ],
   "source": [
    "print(f'output_courses: {output_courses.size()}')\n",
    "print(f'output_gpas: {output_gpas.size()}')\n",
    "print(f'output_courses_lsm: {output_courses_lsm.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert output_courses.isnan().sum().item() == 0, \"nan values in output_courses\"\n",
    "assert output_gpas.isnan().sum().item() == 0, \"nan values in output_gpas\"\n",
    "assert output_courses_lsm.isnan().sum().item() == 0, \"nan values in output_courses_lsm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2, device='cuda:0'),\n",
       " tensor([358,  33,  34,  35, 198, 210,  28,  29,  57,  58, 195,  27,  32,  56,\n",
       "          60,  61,  32,  59,  65,  71, 126, 359,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        device='cuda:0'),\n",
       " tensor([0.0000, 0.9302, 1.0000, 0.6977, 1.0000, 1.0000, 0.8605, 0.9302, 0.9302,\n",
       "         0.6977, 0.9302, 0.9302, 0.0000, 0.4651, 0.6977, 0.6977, 0.7674, 0.6977,\n",
       "         0.6977, 0.7674, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000], device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majors[0], src_courses[0], src_gpas[0], src_courses_positions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([358,   1,   2,  23, 102, 125, 359,   0,   0,   0,   0,   0],\n",
       "        device='cuda:0'),\n",
       " tensor([0.0000, 0.9302, 0.9302, 0.9302, 0.9302, 0.9302, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000], device='cuda:0'),\n",
       " tensor([0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_courses[0], target_grades[0], tgt_courses_positions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([139, 139, 223, 223, 250, 250, 250, 316, 317, 335, 344],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_courses.max(dim=1).indices[0].sort().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " 'PSYC 2310',\n",
       " 'PSYC 2317',\n",
       " 'RELS 1304',\n",
       " 'KINE 1118',\n",
       " 'BIOL 1322',\n",
       " '<SOS>',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id_course_map[x.item()] for x in tgt_courses[0].sort().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MUSI 1271',\n",
       " 'MUSI 1271',\n",
       " 'ASTR 1111',\n",
       " 'ASTR 1111',\n",
       " 'PSYC 2306',\n",
       " 'PSYC 2306',\n",
       " 'PSYC 2306',\n",
       " 'ARTS 2304',\n",
       " 'THAR 2347',\n",
       " 'HIST 1302',\n",
       " 'HONS 2329']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id_course_map[x.item()] for x in output_courses.max(dim=1).indices[0].sort().values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (360) must match the size of tensor b (11) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m y_norm \u001b[38;5;241m=\u001b[39m y_oh \u001b[38;5;241m/\u001b[39m y_oh\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Mask the padding values when computing loss\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m course_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcourse_loss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_courses_lsm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_norm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcourse_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcourse_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# GPA loss function\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Mask the padding values when computing loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:470\u001b[0m, in \u001b[0;36mKLDivLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_div\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_target\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:2961\u001b[0m, in \u001b[0;36mkl_div\u001b[1;34m(input, target, size_average, reduce, reduction, log_target)\u001b[0m\n\u001b[0;32m   2958\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2959\u001b[0m         reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m-> 2961\u001b[0m reduced \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_div\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchmean\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2964\u001b[0m     reduced \u001b[38;5;241m=\u001b[39m reduced \u001b[38;5;241m/\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (360) must match the size of tensor b (11) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "course_loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
    "gpa_loss_fn = nn.MSELoss(reduction='none')\n",
    "\n",
    "course_loss_weight = 1\n",
    "\n",
    "# Course prediction loss function\n",
    "# Summing along dimension 1 creates a vector which has a 1 for each\n",
    "# course they actually took. Padding will be counted multiple times to\n",
    "# encourage the model to not over-predict courses.\n",
    "y_oh = F.one_hot(tgt_out, num_classes=n_courses).sum(dim=1)\n",
    "# y_oh = torch.clamp(y_oh, 0, 1)\n",
    "y_norm = y_oh / y_oh.sum(dim=1, keepdim=True)\n",
    "\n",
    "# Mask the padding values when computing loss\n",
    "course_loss = course_loss_fn(output_courses_lsm, y_norm)\n",
    "print(f'course_loss: {course_loss.item()}')\n",
    "\n",
    "# GPA loss function\n",
    "# Mask the padding values when computing loss\n",
    "gpa_loss = gpa_loss_fn(output_gpas.squeeze(2), tgt_grades_out)\n",
    "mask = torch.ones_like(tgt_grades_out)\n",
    "mask[tgt_pos_out == 0] = 0\n",
    "masked_loss = gpa_loss * mask\n",
    "gpa_reduced_loss = masked_loss.sum() / mask.sum()\n",
    "print(f'GPA loss: {gpa_reduced_loss.item()}')\n",
    "\n",
    "loss = course_loss_weight*course_loss + gpa_reduced_loss\n",
    "print(f'loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for training. Several of these would benefit from tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lr_lambda(current_step):\n",
    "    warmup_steps = 500\n",
    "    d_model = model.d_model  # Typically the size of the embedding\n",
    "    \n",
    "    # Ensure current_step is at least 1 to avoid division by zero\n",
    "    current_step = max(current_step, 1)\n",
    "    \n",
    "    arg1 = current_step ** -0.5\n",
    "    arg2 = current_step * (warmup_steps ** -1.5)\n",
    "    return d_model ** -0.5 * min(arg1, arg2)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_loss_fn = nn.NLLLoss(reduction='mean')\n",
    "gpa_loss_fn = nn.MSELoss(reduction='none')\n",
    "\n",
    "course_loss_weight = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device, dataloader, model, course_loss_fn, gpa_loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Put model in training mode\n",
    "    model.train()\n",
    "\n",
    "    # Iterate over batches\n",
    "    for batch, (src_courses, src_courses_positions, tgt_courses, tgt_courses_positions, majors, src_gpas, target_grades) in enumerate(dataloader):\n",
    "        # Shift target to the right\n",
    "        # Input targets to the decoder ignore the last element\n",
    "        # Prediction targets ignore the first element\n",
    "        tgt_courses_input = tgt_courses.detach().clone().to(device)\n",
    "        tgt_grades_input = target_grades.detach().clone().to(device)\n",
    "        tgt_pos_input = tgt_courses_positions.detach().clone().to(device)\n",
    "\n",
    "        # Find index of EOS_IDX in tgt_courses\n",
    "        eos_tgt_loc = (tgt_courses_input == EOS_IDX).nonzero()\n",
    "        tgt_courses_input[eos_tgt_loc[:, 0], eos_tgt_loc[:, 1]] = PAD_IDX\n",
    "        tgt_grades_input[eos_tgt_loc[:, 0], eos_tgt_loc[:, 1]] = 0.\n",
    "        tgt_pos_input[eos_tgt_loc[:, 0], eos_tgt_loc[:, 1]] = 0\n",
    "\n",
    "        # Now trim off the last element\n",
    "        tgt_courses_input = tgt_courses_input[:, :-1].to(device)\n",
    "        tgt_grades_input = tgt_grades_input[:, :-1].to(device)\n",
    "        tgt_pos_input = tgt_pos_input[:, :-1].to(device)\n",
    "\n",
    "        tgt_out = tgt_courses[:, 1:].to(device) \n",
    "        tgt_grades_out = target_grades[:, 1:].to(device)\n",
    "        tgt_pos_out = tgt_courses_positions[:, 1:].to(device)\n",
    "\n",
    "        # Place on device\n",
    "        src_courses = src_courses.to(device)\n",
    "        src_courses_positions = src_courses_positions.to(device)\n",
    "        majors = majors.to(device)\n",
    "        src_gpas = src_gpas.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        output_courses_lsm, output_gpas, output_courses = model(major=majors,\n",
    "                                                                src_courses=src_courses, \n",
    "                                                                tgt_courses=tgt_courses_input, \n",
    "                                                                src_gpas=src_gpas, \n",
    "                                                                tgt_gpas=tgt_grades_input, \n",
    "                                                                src_courses_positions=src_courses_positions, \n",
    "                                                                tgt_courses_positions=tgt_pos_input)\n",
    "\n",
    "\n",
    "        # Mask the padding values when computing loss\n",
    "        course_loss = course_loss_fn(output_courses_lsm, tgt_out)\n",
    "\n",
    "        # GPA loss function\n",
    "        # Mask the padding values when computing loss\n",
    "        gpa_loss = gpa_loss_fn(output_gpas.squeeze(2), tgt_grades_out)\n",
    "        mask = torch.ones_like(tgt_grades_out)\n",
    "        mask[tgt_pos_out == 0] = 0\n",
    "        masked_loss = gpa_loss * mask\n",
    "        gpa_reduced_loss = masked_loss.sum() / mask.sum()\n",
    "\n",
    "        loss = course_loss_weight*course_loss + gpa_reduced_loss\n",
    "\n",
    "        # Backprop\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr'] \n",
    "\n",
    "        if batch % 200 == 0:\n",
    "            loss_val, current = loss.item(), (batch + 1) * len(src_courses)\n",
    "            course_weight_pct = course_loss_weight*course_loss / loss\n",
    "            gpa_weight_pct = gpa_reduced_loss / loss\n",
    "            print(f'loss: {loss_val:>7f} [{current/size:.1%}] ({course_weight_pct:.1%} course, {gpa_weight_pct:.1%} gpa)')\n",
    "    print(f'LR = {current_lr}')\n",
    "    scheduler.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(device, dataloader, model):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Make predictions but don't calculate gradients on forward pass\n",
    "    with torch.no_grad():\n",
    "        # Iterate over batches\n",
    "        for batch, (src_courses, src_courses_positions, tgt_courses, tgt_courses_positions, majors, src_gpas, target_grades) in enumerate(dataloader):\n",
    "            # Shift target to the right\n",
    "            # Input targets to the decoder ignore the last element\n",
    "            # Prediction targets ignore the first element\n",
    "            tgt_courses_input = tgt_courses.detach().clone().to(device)\n",
    "            tgt_grades_input = target_grades.detach().clone().to(device)\n",
    "            tgt_pos_input = tgt_courses_positions.detach().clone().to(device)\n",
    "\n",
    "            # Find index of EOS_IDX in tgt_courses\n",
    "            eos_tgt_loc = (tgt_courses_input == EOS_IDX).nonzero()\n",
    "            tgt_courses_input[eos_tgt_loc[:, 0], eos_tgt_loc[:, 1]] = PAD_IDX\n",
    "            tgt_grades_input[eos_tgt_loc[:, 0], eos_tgt_loc[:, 1]] = 0.\n",
    "            tgt_pos_input[eos_tgt_loc[:, 0], eos_tgt_loc[:, 1]] = 0\n",
    "\n",
    "            # Now trim off the last element\n",
    "            tgt_courses_input = tgt_courses_input[:, :-1].to(device)\n",
    "            tgt_grades_input = tgt_grades_input[:, :-1].to(device)\n",
    "            tgt_pos_input = tgt_pos_input[:, :-1].to(device)\n",
    "\n",
    "            tgt_out = tgt_courses[:, 1:].to(device) \n",
    "            tgt_grades_out = target_grades[:, 1:].to(device)\n",
    "            tgt_pos_out = tgt_courses_positions[:, 1:].to(device)\n",
    "\n",
    "            # Place on device\n",
    "            src_courses = src_courses.to(device)\n",
    "            src_courses_positions = src_courses_positions.to(device)\n",
    "            majors = majors.to(device)\n",
    "            src_gpas = src_gpas.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output_courses_lsm, output_gpas, output_courses = model(major=majors,\n",
    "                                                                    src_courses=src_courses, \n",
    "                                                                    tgt_courses=tgt_courses_input, \n",
    "                                                                    src_gpas=src_gpas, \n",
    "                                                                    tgt_gpas=tgt_grades_input, \n",
    "                                                                    src_courses_positions=src_courses_positions, \n",
    "                                                                    tgt_courses_positions=tgt_pos_input)\n",
    "\n",
    "            # # Course prediction loss\n",
    "            course_loss = course_loss_fn(output_courses_lsm, tgt_out)\n",
    "\n",
    "            # GPA loss function\n",
    "            # Mask the padding values when computing loss\n",
    "            gpa_loss = gpa_loss_fn(output_gpas.squeeze(2), tgt_grades_out)\n",
    "            mask = torch.ones_like(tgt_grades_out)\n",
    "            mask[tgt_pos_out == 0] = 0\n",
    "            masked_loss = gpa_loss * mask\n",
    "            gpa_reduced_loss = masked_loss.sum() / mask.sum()\n",
    "\n",
    "            loss = course_loss_weight*course_loss + gpa_reduced_loss\n",
    "        \n",
    "            # Get class predictions\n",
    "            pred_courses = output_courses.argmax(dim=1)\n",
    "\n",
    "\n",
    "            # Compute IOU for courses for the whole batch\n",
    "            # mean_iou = compute_iou(pred_courses, tgt_out, PAD_IDX, EOS_IDX, n_courses-2, True)\n",
    "\n",
    "            # Get predicted grades\n",
    "            # gpas_mask = tgt_pos_out != 0\n",
    "\n",
    "            # Compute MAE\n",
    "            # mae = masked_mae(output_gpas.squeeze(2), tgt_grades_out, gpas_mask)      \n",
    "    \n",
    "    # print(f'Loss: {loss:.4f}, Mean IOU: {mean_iou:.1%}, MAE: {mae:.4f} \\n')\n",
    "    print(f'Sample')\n",
    "    print(f'\\tPredicted: {pred_courses[0].squeeze()}')\n",
    "    print(f'\\tActual: {tgt_out[0].squeeze()}')\n",
    "    print(f'Test loss: {loss.item():>7f}')\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:5109: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample\n",
      "\tPredicted: tensor([ 17,  32,  96, 359, 359,   0,   0,   0,   0,   0,   0],\n",
      "       device='cuda:0')\n",
      "\tActual: tensor([ 61, 120, 167, 231, 359,   0,   0,   0,   0,   0,   0],\n",
      "       device='cuda:0')\n",
      "Test loss: 2.143216\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Sample\n",
      "\tPredicted: tensor([ 17, 359,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       device='cuda:0')\n",
      "\tActual: tensor([ 17, 359,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       device='cuda:0')\n",
      "Test loss: 1.837468\n",
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# train_loss = train(device, train_dataloader, model, course_loss_fn, gpa_loss_fn, optimizer)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m     11\u001b[0m test_losses\u001b[38;5;241m.\u001b[39mappend(test_loss)\n",
      "Cell \u001b[1;32mIn[18], line 38\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(device, dataloader, model)\u001b[0m\n\u001b[0;32m     35\u001b[0m src_gpas \u001b[38;5;241m=\u001b[39m src_gpas\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m output_courses_lsm, output_gpas, output_courses \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmajors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43msrc_courses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_courses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mtgt_courses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_courses_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43msrc_gpas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_gpas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mtgt_gpas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_grades_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43msrc_courses_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_courses_positions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mtgt_courses_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_pos_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# # Course prediction loss\u001b[39;00m\n\u001b[0;32m     47\u001b[0m course_loss \u001b[38;5;241m=\u001b[39m course_loss_fn(output_courses_lsm, tgt_out)\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[1;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[1;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\parallel\\parallel_apply.py:98\u001b[0m, in \u001b[0;36mparallel_apply\u001b[1;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[0;32m     92\u001b[0m threads \u001b[38;5;241m=\u001b[39m [threading\u001b[38;5;241m.\u001b[39mThread(target\u001b[38;5;241m=\u001b[39m_worker,\n\u001b[0;32m     93\u001b[0m                             args\u001b[38;5;241m=\u001b[39m(i, module, \u001b[38;5;28minput\u001b[39m, kwargs, device, stream))\n\u001b[0;32m     94\u001b[0m            \u001b[38;5;28;01mfor\u001b[39;00m i, (module, \u001b[38;5;28minput\u001b[39m, kwargs, device, stream) \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m     95\u001b[0m            \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(modules, inputs, kwargs_tup, devices, streams))]\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[1;32m---> 98\u001b[0m     \u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m    100\u001b[0m     thread\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:969\u001b[0m, in \u001b[0;36mThread.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m _limbo[\u001b[38;5;28mself\u001b[39m]\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_started\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}\\n-------------------------------')\n",
    "    train_loss = train(device, train_dataloader, model, course_loss_fn, gpa_loss_fn, optimizer)\n",
    "    test_loss = test(device, test_dataloader, model)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(test_losses, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src_courses, src_gpas, major, src_mask, src_courses_positions, src_key_padding_mask, max_len=15, start_symbol=SOS_IDX):\n",
    "    model.eval()\n",
    "\n",
    "    batch_size = src_courses.size(0)\n",
    "    # Get the max value from each row\n",
    "    current_semester = src_courses_positions.max(dim=1).values\n",
    "\n",
    "    # print(f'src_mask: {src_mask}')\n",
    "    # print(f'src_key_padding_mask: {src_key_padding_mask}')\n",
    "    # print(f'src_courses_positions: {src_courses_positions}')\n",
    "\n",
    "    # Encode to get memory\n",
    "    memory = model.encode(major, \n",
    "                          src_courses, \n",
    "                          src_gpas, \n",
    "                          src_courses_positions, \n",
    "                          src_mask, \n",
    "                          src_key_padding_mask).to(device)\n",
    "    \n",
    "    # Start with the SOS token\n",
    "    courses_seq = torch.ones(batch_size, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    gpas_seq = torch.zeros(batch_size, 1).type(torch.float).to(device)\n",
    "    courses_pos = torch.zeros(batch_size, 1).type(torch.long).to(device)\n",
    "    # print(f'courses_seq: {courses_seq.squeeze()}')\n",
    "    # print(f'gpas_seq: {gpas_seq.squeeze()}')\n",
    "    # print(f'courses_pos: {courses_pos.squeeze()}')\n",
    "    for i in range(max_len-1):\n",
    "        current_len = courses_seq.size(1)\n",
    "        tgt_mask = dataset.generate_tgt_mask(current_len).to(device)\n",
    "        # tgt_mask = torch.zeros(2*current_len, 2*current_len).bool().to(device)\n",
    "        tgt_key_padding_mask = dataset.generate_tgt_padding_masks(courses_seq, PAD_IDX).to(device)\n",
    "\n",
    "        # print(f'courses_seq[0]: {courses_seq[0]}')\n",
    "        # print(f'tgt_mask[0]: {tgt_mask[0]}')\n",
    "        # print(f'tgt_key_padding_mask[0]: {tgt_key_padding_mask[0]}')\n",
    "        # print(f'tgt_mask: {tgt_mask}')\n",
    "        # print(f'tgt_key_padding_mask: {tgt_key_padding_mask}')\n",
    "\n",
    "        # Decode memory and last generated token(s)\n",
    "        # print(f'memory: {memory.size()}')\n",
    "        # print(f'courses_seq: {courses_seq.size()}')\n",
    "        # print(f'gpas_seq: {gpas_seq.size()}')\n",
    "        # print(f'courses_pos: {courses_pos.size()}')\n",
    "        # print(f'tgt_mask: {tgt_mask.size()}')\n",
    "        # print(f'current_len: {current_len}')\n",
    "\n",
    "        out = model.decode(memory, \n",
    "                           courses_seq, \n",
    "                           gpas_seq, \n",
    "                           courses_pos, \n",
    "                           tgt_mask, \n",
    "                           tgt_key_padding_mask)\n",
    "        # print(f'out[0]: {out[0]}')\n",
    "        # print(f'out[1]: {out[1]}')\n",
    "        # print(f'out: {out.size()}')\n",
    "        # print(f'out_slice: {out[0, i, :].squeeze()}')\n",
    "        # print(f'out_slice_gpa: {out[0, i+current_len, :].squeeze()}')\n",
    "\n",
    "        # Take the last token's output\n",
    "        # prob_courses, prob_gpas = model.generator(out[:, [i, i+current_len], :], 1)\n",
    "        # print(f'out: {out[0, ]}')\n",
    "        prob_courses, prob_gpas = model.generator(out, current_len)\n",
    "        # HACK: Don't let it predict EOS_IDX\n",
    "        # prob_courses[:, EOS_IDX, :] = 0\n",
    "        # print(f'prob_courses: {prob_courses.size()}')\n",
    "        _, next_course = torch.max(prob_courses[:, :, -1], dim=1)\n",
    "        next_course = next_course.unsqueeze(1)\n",
    "        # print(f'prob_gpas: {prob_gpas.size()}')\n",
    "        next_gpa = prob_gpas[:, -1, :]\n",
    "\n",
    "        # print(f'courses_seq: {courses_seq.size()}')\n",
    "        # print(f'prob_courses: {prob_courses.size()}')\n",
    "        # print(f'prob_courses: {prob_courses.squeeze()}')\n",
    "        # print(f'gpas_seq: {gpas_seq.size()}')\n",
    "        # print(f'prob_gpas: {prob_gpas.size()}')\n",
    "        # print(f'next_course: {next_course.size()}')\n",
    "        # print(f'next_gpa: {next_gpa.size()}')\n",
    "        # print(f'next_course: {next_course.squeeze()}')\n",
    "\n",
    "        # print(f'prob_gpas: {prob_gpas.squeeze()}')\n",
    "        # print(f'next_course: {next_course.squeeze()}')\n",
    "        \n",
    "        # courses_seq and gpas_seq grows in sequence length dimension\n",
    "        courses_seq = torch.cat([courses_seq, next_course], dim=1)\n",
    "        gpas_seq = torch.cat([gpas_seq, next_gpa], dim=1)\n",
    "        # If next_course is not PAD_IDX, set the courses_pos to current_semestser. Otherwise, set it to zero.\n",
    "        # is_pad_course = (courses_seq == PAD_IDX) | (courses_seq == EOS_IDX)\n",
    "        # current_pos = torch.where(is_pad_course, torch.zeros_like(courses_seq), current_semester.unsqueeze(1))\n",
    "        # courses_pos = torch.cat([courses_pos, current_pos], dim=1)\n",
    "        courses_pos = torch.cat([courses_pos, current_semester.unsqueeze(1)], dim=1)\n",
    "        # print(f'courses_seq: {courses_seq}')\n",
    "        # print()\n",
    "        \n",
    "        # Check if all sequences in the batch have reached EOS\n",
    "        # if ((next_course == PAD_IDX) | (next_course == EOS_IDX)).all():\n",
    "        #     break\n",
    "    return courses_seq, gpas_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual function to translate input sentence into target language\n",
    "def predict(model, major, src_courses, src_gpas, src_courses_positions):\n",
    "    # Source mask\n",
    "    src_seq_len = 1 + src_courses.size(1) + src_gpas.size(1)\n",
    "    src_mask = dataset.generate_src_mask(src_seq_len).to(device)\n",
    "    \n",
    "    # Padding masks\n",
    "    src_key_padding_mask = dataset.generate_src_padding_masks(src_courses, major, PAD_IDX).to(device)\n",
    "\n",
    "    # Place on device\n",
    "    major = major.to(device)\n",
    "    src_courses = src_courses.to(device)\n",
    "    src_gpas = src_gpas.to(device)\n",
    "    src_courses_positions = src_courses_positions.to(device)\n",
    "    src_key_padding_mask = src_key_padding_mask.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_courses, pred_gpas = greedy_decode(model, \n",
    "                                                src_courses, \n",
    "                                                src_gpas,\n",
    "                                                major,\n",
    "                                                src_mask,\n",
    "                                                src_courses_positions,\n",
    "                                                src_key_padding_mask)\n",
    "    return pred_courses, pred_gpas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a batch from the test set\n",
    "for src_courses, src_courses_positions, tgt_courses, tgt_courses_positions, majors, src_gpas, target_grades in test_dataloader:\n",
    "    pred_courses, pred_gpas = predict(model, majors, src_courses, src_gpas, src_courses_positions)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Major: Psychology\n",
      "Actual source courses: ['<SOS>', 'PSYC 2317', 'COMM 1317', 'FSTY 1310', 'PSYC 2307', 'FSTY 1311', 'ENGW 1302', 'CULF 1320', 'APSC 1110', 'PSYC 2305', 'PSYC 2316', 'PSYC 3319', '<OTHER>', 'CULF 2321', 'CULF 1318', 'PSYC 2306', 'PSYC 3438', '<OTHER>', 'SCIE 2320', 'PHIL 1301', 'PSYC 2308', 'PSYC 2321', 'PHIL 2329', 'SPAN 1311', 'CULF 3330', 'PSYC 4344', 'PSYC 3438', 'PSYC 4343', 'RELS 1304', 'SPAN 1312', 'BIOL 1310', '<OTHER>', 'SABR 2150', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Actual target courses: ['<SOS>', '<OTHER>', 'PSYC 4359', 'KINE 1119', 'PSYC 4360', 'PSYC 2349', 'KINE 1109', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Predicted target courses: ['<SOS>', 'PSYC 4341', 'PSYC 4359', 'PSYC 4442', 'PSYC 4360', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "actual_src_courses = [id_course_map[x.item()] for x in src_courses[0]]\n",
    "actual_tgt_courses = [id_course_map[x.item()] for x in tgt_courses[0]]\n",
    "pred_tgt_courses = [id_course_map[x.item()] for x in pred_courses[0]]\n",
    "\n",
    "print(f'Major: {id_major_map[majors[0].item()]}')\n",
    "print(f'Actual source courses: {actual_src_courses}')\n",
    "print(f'Actual target courses: {actual_tgt_courses}')\n",
    "print(f'Predicted target courses: {pred_tgt_courses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([358,   2,  28, 162, 207, 211,  90,  94, 163, 193, 196,   4,  17,  98,\n",
       "          99, 250,   6,  17,  97, 168, 206,   3,  38,  43, 177, 204,   6,  11,\n",
       "          23,  44, 195,  17, 124, 359,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " tensor([358,  17,  18, 151, 209, 261, 288, 359,   0,   0,   0,   0]),\n",
       " tensor([358,   7,  18,  19, 209, 359, 359, 359, 359, 359, 359, 359, 359, 359,\n",
       "         359], device='cuda:0'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_courses[0], tgt_courses[0], pred_courses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAR(device, dataloader, model, SOS_TOKEN, EOS_TOKEN, course_map):\n",
    "    model.to(device)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    total_iou = 0\n",
    "    total_sequences = 0\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients during inference\n",
    "        for batch, (X, X_pos, y, y_pos, X_pad_mask, y_pad_mask, majors, input_grades, target_grades) in enumerate(dataloader):\n",
    "            max_len = y.size(1)\n",
    "            batch_size = X.size(0)\n",
    "\n",
    "            # Initialize EOS tracking tensor\n",
    "            eos_reached = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "            # Initialize empty tensors to hold predictions\n",
    "            generated_courses = torch.zeros(batch_size, max_len, device=device, dtype=torch.long)\n",
    "            generated_gpas = torch.zeros(batch_size, max_len, device=device)\n",
    "\n",
    "            # Move data to device\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            X_pos = X_pos.to(device)\n",
    "            y_pos = y_pos.to(device)\n",
    "            X_pad_mask = X_pad_mask.to(device)\n",
    "            y_pad_mask = y_pad_mask.to(device)\n",
    "            majors = majors.to(device)\n",
    "            input_grades = input_grades.to(device)\n",
    "            target_grades = target_grades.to(device)\n",
    "\n",
    "            # Start with the SOS token for each sequence in the batch\n",
    "            tgt_courses = torch.full((batch_size, 1), SOS_TOKEN, dtype=torch.long, device=device)\n",
    "            tgt_gpas = torch.zeros(batch_size, 1, device=device)\n",
    "\n",
    "            for t in range(1, max_len + 1):\n",
    "                current_tgt_pos = y_pos[:, :t]\n",
    "                current_tgt_pad_mask = y_pad_mask[:, :t]\n",
    "\n",
    "                output_courses_lsm, output_gpas, _ = model(major=majors,\n",
    "                                                            src_courses=X, \n",
    "                                                            tgt_courses=tgt_courses, \n",
    "                                                            src_gpas=input_grades, \n",
    "                                                            tgt_gpas=tgt_gpas, \n",
    "                                                            src_courses_positions=X_pos, \n",
    "                                                            tgt_courses_positions=current_tgt_pos,\n",
    "                                                            src_courses_key_padding_mask=X_pad_mask,\n",
    "                                                            tgt_courses_key_padding_mask=current_tgt_pad_mask)\n",
    "\n",
    "                # Get the next course and GPA predictions\n",
    "                next_courses = output_courses_lsm[:, :, -1].argmax(dim=1)\n",
    "                next_gpa = output_gpas[:, -1, :].unsqueeze(1)\n",
    "\n",
    "                # Store the predictions\n",
    "                generated_courses[:, t-1] = next_courses\n",
    "                generated_gpas[:, t-1] = next_gpa.squeeze()\n",
    "\n",
    "                # Prepare the next step's inputs\n",
    "                tgt_courses = torch.cat([tgt_courses, next_courses.unsqueeze(1)], dim=1)\n",
    "                tgt_gpas = torch.cat([tgt_gpas, next_gpa.squeeze(1)], dim=1)\n",
    "\n",
    "                eos_reached |= (next_courses == EOS_TOKEN)\n",
    "\n",
    "                if eos_reached.all():\n",
    "                    break\n",
    "\n",
    "            # Calculate IoU for each sequence\n",
    "            for i in range(batch_size):\n",
    "                generated_set = set(generated_courses[i].cpu().numpy())\n",
    "                target_set = set(y[i].cpu().numpy())\n",
    "                generated_set.discard(0)  # Remove padding token from consideration\n",
    "                target_set.discard(0)  # Remove padding token from consideration\n",
    "\n",
    "                intersection = len(generated_set.intersection(target_set))\n",
    "                union = len(generated_set.union(target_set))\n",
    "                iou = intersection / union if union > 0 else 0.0\n",
    "                total_iou += iou\n",
    "                total_sequences += 1\n",
    "\n",
    "                actual_courses = [course_map[course] for course in y[i].cpu().numpy() if course != 0]\n",
    "                predicted_courses = [course_map[course] for course in generated_courses[i].cpu().numpy() if course != 0]\n",
    "\n",
    "                print(f\"Sample {i+1}:\")\n",
    "                print(f\"Actual Courses: {actual_courses}\")\n",
    "                print(f\"Predicted Courses: {predicted_courses}\")\n",
    "                print(f\"IoU: {iou:.2%}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "    avg_iou = total_iou / total_sequences\n",
    "    print(f\"Average IoU for the batch: {avg_iou:.2%}\")\n",
    "    \n",
    "    return avg_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Actual Courses: ['<SOS>', 'ARTS 1311', 'ARTS 1316', 'SPAN 1311', 'VGAM 1303', 'WRIT 2302', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 2:\n",
      "Actual Courses: ['<SOS>', 'ACCT 2301', 'BUSI 2303', 'BUSI 2305', 'BUSI 3330', 'MGMT 3334', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 3:\n",
      "Actual Courses: ['<SOS>', 'COSC 3344', 'COSC 3344', 'COSC 4343', 'COSC 4343', 'Other', 'Other', 'Other', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 16.67%\n",
      "--------------------------------------------------\n",
      "Sample 4:\n",
      "Actual Courses: ['<SOS>', 'PSYC 2307', 'PSYC 3438', 'PHIL 3311', 'BIOL 2135', 'BIOL 2335', 'CPAM 1110', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 5:\n",
      "Actual Courses: ['<SOS>', 'Other', 'Other', 'Other', 'POLS 3328', 'POLS 4342', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 16.67%\n",
      "--------------------------------------------------\n",
      "Sample 6:\n",
      "Actual Courses: ['<SOS>', 'COSC 3344', 'COSC 4343', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 16.67%\n",
      "--------------------------------------------------\n",
      "Sample 7:\n",
      "Actual Courses: ['<SOS>', 'BIOL 1107', 'BIOL 1307', 'Other', 'COSC 4257', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 14.29%\n",
      "--------------------------------------------------\n",
      "Sample 8:\n",
      "Actual Courses: ['<SOS>', 'Other', 'ENGL 2323', 'Other', 'JOUR 2321', 'HONS 3329', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 14.29%\n",
      "--------------------------------------------------\n",
      "Sample 9:\n",
      "Actual Courses: ['<SOS>', 'Other', 'PSYC 2301', 'BIOL 1310', 'MATH 309', 'APSC 1110', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 12.50%\n",
      "--------------------------------------------------\n",
      "Sample 10:\n",
      "Actual Courses: ['<SOS>', 'CRIJ 2313', 'POLS 3328', 'COMM 1317', 'WRIT 1301', 'SCIE 2324', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 11:\n",
      "Actual Courses: ['<SOS>', 'BUSI 3330', 'BUSI 3333', 'MGMT 3334', 'MGMT 3340', 'MKTG 3343', 'COSC 1305', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 12:\n",
      "Actual Courses: ['<SOS>', 'ACCT 2303', 'BUSI 3328', 'BUSI 3330', 'FINC 3330', 'MGMT 3334', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 13:\n",
      "Actual Courses: ['<SOS>', 'PSYC 2308', 'PSYC 2316', 'PSYC 2317', 'FREN 1311', 'PHIL 2329', 'CULF 3330', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 14:\n",
      "Actual Courses: ['<SOS>', 'ARTS 2303', 'Other', 'VISU 4340', 'KINE 1118', 'KINE 1320', 'KINE 2324', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 11.11%\n",
      "--------------------------------------------------\n",
      "Sample 15:\n",
      "Actual Courses: ['<SOS>', 'ARTS 2399', 'JOUR 2321', 'ASTR 1111', 'ASTR 1311', 'Other', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 12.50%\n",
      "--------------------------------------------------\n",
      "Sample 16:\n",
      "Actual Courses: ['<SOS>', 'WRIT 2302', 'BDMM 2301', 'BUSI 1301', 'COSC 1305', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 17:\n",
      "Actual Courses: ['<SOS>', 'ARTS 1316', 'ENGL 2324', 'BUSI 2305', 'ECON 2301', 'COSC 1305', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 18:\n",
      "Actual Courses: ['<SOS>', 'SPAN 3330', 'ECON 2301', 'COSC 1305', 'MATH 1324', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 19:\n",
      "Actual Courses: ['<SOS>', 'COMM 1306', 'Other', 'WRIT 2302', 'MKTG 2301', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 14.29%\n",
      "--------------------------------------------------\n",
      "Sample 20:\n",
      "Actual Courses: ['<SOS>', 'ENSP 2324', 'PSYC 2310', 'FREN 1312', 'MATH 309', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 21:\n",
      "Actual Courses: ['<SOS>', 'SOCI 1301', 'BUSI 1301', 'KINE 1311', 'MATH 309', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 12.50%\n",
      "--------------------------------------------------\n",
      "Sample 22:\n",
      "Actual Courses: ['<SOS>', 'Other', 'PSYC 4341', 'SOCW 1301', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 16.67%\n",
      "--------------------------------------------------\n",
      "Sample 23:\n",
      "Actual Courses: ['<SOS>', 'PHIL 2329', 'ACCT 2303', 'BUSI 2303', 'BUSI 3328', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 24:\n",
      "Actual Courses: ['<SOS>', 'ARTS 2399', 'ACCT 3331', 'ACCT 3333', 'FINC 3330', 'MGMT 3334', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 25:\n",
      "Actual Courses: ['<SOS>', 'Other', 'GDES 3304', 'MUSI 1281', 'WRIT 2312', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 14.29%\n",
      "--------------------------------------------------\n",
      "Sample 26:\n",
      "Actual Courses: ['<SOS>', 'HIST 2329', 'POLS 2341', 'Other', 'RELS 1316', 'BIOL 1310', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 12.50%\n",
      "--------------------------------------------------\n",
      "Sample 27:\n",
      "Actual Courses: ['<SOS>', 'PSYC 3319', 'COMM 3344', 'ACCT 2303', 'BUSI 2303', 'BUSI 3330', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 28:\n",
      "Actual Courses: ['<SOS>', 'Other', 'ENSP 2349', 'Other', 'POLS 3328', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 16.67%\n",
      "--------------------------------------------------\n",
      "Sample 29:\n",
      "Actual Courses: ['<SOS>', 'Other', 'PSYC 2316', 'WRIT 2302', 'COSC 1305', 'MATH 1324', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 12.50%\n",
      "--------------------------------------------------\n",
      "Sample 30:\n",
      "Actual Courses: ['<SOS>', 'COMM 1317', 'BIOL 1107', 'BIOL 1307', 'MATH 2312', 'FSEM 1409', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 31:\n",
      "Actual Courses: ['<SOS>', 'Other', 'PSYC 2326', 'PSYC 4359', 'BIOL 2334', 'CHEM 1140', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 12.50%\n",
      "--------------------------------------------------\n",
      "Sample 32:\n",
      "Actual Courses: ['<SOS>', 'RELS 1304', 'MKTG 2301', 'COSC 1305', 'MATH 1324', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 1:\n",
      "Actual Courses: ['<SOS>', 'COMM 1317', 'RELS 2321', 'ECON 2301', 'COSC 1305', 'FSEM 1401', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 2:\n",
      "Actual Courses: ['<SOS>', 'CRIJ 1302', 'CRIJ 4345', 'Other', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 16.67%\n",
      "--------------------------------------------------\n",
      "Sample 3:\n",
      "Actual Courses: ['<SOS>', 'ENGW 1301', 'COSC 1123', 'COSC 1323', 'Other', 'Other', 'HONS 1340', 'HONS 2160', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 11.11%\n",
      "--------------------------------------------------\n",
      "Sample 4:\n",
      "Actual Courses: ['<SOS>', 'CULF 1319', 'Other', 'BUSI 2305', 'COSC 2125', 'COSC 2325', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 12.50%\n",
      "--------------------------------------------------\n",
      "Sample 5:\n",
      "Actual Courses: ['<SOS>', 'Other', 'Other', 'Other', 'BUSI 1301', 'ECON 2301', 'HONS 2160', 'HONS 2326', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 12.50%\n",
      "--------------------------------------------------\n",
      "Sample 6:\n",
      "Actual Courses: ['<SOS>', 'GDES 1314', 'GERM 1312', 'Other', 'MKTG 2301', 'SCIE 2324', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 12.50%\n",
      "--------------------------------------------------\n",
      "Sample 7:\n",
      "Actual Courses: ['<SOS>', 'SOCI 1301', 'SOCW 1301', 'AHMX 2314', 'BIOL 1310', 'FSEM 1410', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 8:\n",
      "Actual Courses: ['<SOS>', 'Other', 'Other', 'Other', 'HONS 4370', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 20.00%\n",
      "--------------------------------------------------\n",
      "Sample 9:\n",
      "Actual Courses: ['<SOS>', 'ENGL 2324', 'JOUR 2321', 'PHIL 2329', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 14.29%\n",
      "--------------------------------------------------\n",
      "Sample 10:\n",
      "Actual Courses: ['<SOS>', 'ENGW 1302', 'SPAN 1312', 'MKTG 2301', 'MATH 2312', 'FSTY 1122', 'FSTY 1322', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 11:\n",
      "Actual Courses: ['<SOS>', 'Other', 'PHOT 3322', 'Other', 'VISU 3335', 'VISU 4340', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 14.29%\n",
      "--------------------------------------------------\n",
      "Sample 12:\n",
      "Actual Courses: ['<SOS>', 'GLST 1322', 'POLS 2332', 'POLS 2341', 'ARTS 2399', 'WRIT 2302', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 13:\n",
      "Actual Courses: ['<SOS>', 'COMM 1317', 'ECON 2301', 'COSC 1123', 'COSC 1323', 'MATH 2312', 'CULF 1320', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 14:\n",
      "Actual Courses: ['<SOS>', 'Other', 'Other', 'Other', 'CHEM 3125', 'CHEM 3325', 'MATH 2413', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 14.29%\n",
      "--------------------------------------------------\n",
      "Sample 15:\n",
      "Actual Courses: ['<SOS>', 'ENGL 2324', 'Other', 'COSC 4360', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 16.67%\n",
      "--------------------------------------------------\n",
      "Sample 16:\n",
      "Actual Courses: ['<SOS>', 'Other', 'Other', 'BIOL 2334', 'CHEM 2123', 'CHEM 2323', 'MATH 2413', 'CULF 2321', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 11.11%\n",
      "--------------------------------------------------\n",
      "Sample 17:\n",
      "Actual Courses: ['<SOS>', 'WRIT 2302', 'MGMT 3334', 'BIOL 2334', 'COSC 1305', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 18:\n",
      "Actual Courses: ['<SOS>', 'ARTS 2399', 'COMM 1317', 'WRIT 1301', 'BUSI 1301', 'FSEM 1401', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 19:\n",
      "Actual Courses: ['<SOS>', 'Other', 'GDES 2331', 'GDES 3304', 'Other', 'COSC 1301', 'CULF 2321', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 12.50%\n",
      "--------------------------------------------------\n",
      "Sample 20:\n",
      "Actual Courses: ['<SOS>', 'EDUC 1111', 'WRIT 1301', 'ECON 2301', 'MGMT 2301', 'MATH 1314', 'FSEM 1401', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 21:\n",
      "Actual Courses: ['<SOS>', 'COMM 1317', 'WRIT 1301', 'BUSI 1301', 'MKTG 2301', 'FSEM 1407', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 22:\n",
      "Actual Courses: ['<SOS>', 'Other', 'Other', 'POLS 2332', 'Other', 'ARTS 1316', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 16.67%\n",
      "--------------------------------------------------\n",
      "Sample 23:\n",
      "Actual Courses: ['<SOS>', 'Other', 'BIOL 2113', 'BIOL 2135', 'BIOL 2335', 'CHEM 2123', 'CHEM 2323', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 11.11%\n",
      "--------------------------------------------------\n",
      "Sample 24:\n",
      "Actual Courses: ['<SOS>', 'PSYC 2301', 'SOCI 1301', 'KINE 2324', 'RELS 2323', 'SPAN 1312', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 25:\n",
      "Actual Courses: ['<SOS>', 'CRIJ 3331', 'Other', 'ARTS 1316', 'Other', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 16.67%\n",
      "--------------------------------------------------\n",
      "Sample 26:\n",
      "Actual Courses: ['<SOS>', 'ARTS 1311', 'ARTS 1316', 'VGAM 1303', 'MATH 1314', 'HONS 2312', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 27:\n",
      "Actual Courses: ['<SOS>', 'RELS 1304', 'BIOL 2334', 'Other', 'BIOL 4157', 'CHEM 2120', 'CHEM 2320', 'CULF 1320', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 10.00%\n",
      "--------------------------------------------------\n",
      "Sample 28:\n",
      "Actual Courses: ['<SOS>', 'POLS 2332', 'POLS 2341', 'CULF 1319', 'MUSI 1281', 'CULF 2321', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 29:\n",
      "Actual Courses: ['<SOS>', 'PSYC 2310', 'PSYC 2321', 'PSYC 4359', 'BIOL 2334', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 12.50%\n",
      "--------------------------------------------------\n",
      "Sample 30:\n",
      "Actual Courses: ['<SOS>', 'ENSP 1304', 'ENSP 2324', 'SOCI 1301', 'Other', 'WRIT 2302', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 12.50%\n",
      "--------------------------------------------------\n",
      "Sample 31:\n",
      "Actual Courses: ['<SOS>', 'PSYC 2301', 'BIOL 1107', 'BIOL 1307', 'CHEM 1140', 'CHEM 1340', 'MATH 2312', 'HONS 2160', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 0.00%\n",
      "--------------------------------------------------\n",
      "Sample 32:\n",
      "Actual Courses: ['<SOS>', 'BUSI 3328', 'MATH 3320', 'MATH 4157', 'Other', 'Other', 'Other', '<EOS>']\n",
      "Predicted Courses: ['ENGL 2301', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other', 'Other']\n",
      "IoU: 14.29%\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpredictAR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOS_TOKEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEOS_TOKEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_course_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 39\u001b[0m, in \u001b[0;36mpredictAR\u001b[1;34m(device, dataloader, model, SOS_TOKEN, EOS_TOKEN, course_map)\u001b[0m\n\u001b[0;32m     36\u001b[0m current_tgt_pos \u001b[38;5;241m=\u001b[39m y_pos[:, :t]\n\u001b[0;32m     37\u001b[0m current_tgt_pad_mask \u001b[38;5;241m=\u001b[39m y_pad_mask[:, :t]\n\u001b[1;32m---> 39\u001b[0m output_courses_lsm, output_gpas, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmajors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msrc_courses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtgt_courses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_courses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msrc_gpas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_grades\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtgt_gpas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_gpas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msrc_courses_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtgt_courses_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_tgt_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msrc_courses_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_pad_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mtgt_courses_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_tgt_pad_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Get the next course and GPA predictions\u001b[39;00m\n\u001b[0;32m     50\u001b[0m next_courses \u001b[38;5;241m=\u001b[39m output_courses_lsm[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\outcome_modeling\\models\\transformer.py:228\u001b[0m, in \u001b[0;36mTransformerModelWithGrades.forward\u001b[1;34m(self, major, src_courses, tgt_courses, src_gpas, tgt_gpas, src_courses_positions, tgt_courses_positions, src_courses_key_padding_mask, tgt_courses_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    220\u001b[0m tgt_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((tgt_mask, tgt_mask), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# Run through the transformer\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;66;03m# print(f'src_enc: {src_enc.element_size() * src_enc.nelement() / 1024 / 1024} MB')\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# print(f'tgt_enc: {tgt_enc.element_size() * tgt_enc.nelement() / 1024 / 1024} MB')\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# print(f'tgt_mask: {tgt_mask.element_size() * tgt_mask.nelement() / 1024 / 1024} MB')\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# print(f'src_key_padding_mask: {src_key_padding_mask.element_size() * src_key_padding_mask.nelement() / 1024 / 1024} MB')\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# print(f'tgt_key_padding_mask: {tgt_key_padding_mask.element_size() * tgt_key_padding_mask.nelement() / 1024 / 1024} MB')\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m#   tgt_is_causal=True,\u001b[39;49;00m\n\u001b[0;32m    231\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# print(f'output: {output.element_size() * output.nelement() / 1024 / 1024} MB')\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m print_sizes:\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:206\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;129;01mor\u001b[39;00m tgt\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model:\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 206\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(tgt, memory, tgt_mask\u001b[38;5;241m=\u001b[39mtgt_mask, memory_mask\u001b[38;5;241m=\u001b[39mmemory_mask,\n\u001b[0;32m    209\u001b[0m                       tgt_key_padding_mask\u001b[38;5;241m=\u001b[39mtgt_key_padding_mask,\n\u001b[0;32m    210\u001b[0m                       memory_key_padding_mask\u001b[38;5;241m=\u001b[39mmemory_key_padding_mask,\n\u001b[0;32m    211\u001b[0m                       tgt_is_causal\u001b[38;5;241m=\u001b[39mtgt_is_causal, memory_is_causal\u001b[38;5;241m=\u001b[39mmemory_is_causal)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:391\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    388\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 391\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    394\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:685\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m why_not_sparsity_fast_path:\n\u001b[0;32m    684\u001b[0m         merged_mask, mask_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mmerge_masks(src_mask, src_key_padding_mask, src)\n\u001b[1;32m--> 685\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformer_encoder_layer_fwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m            \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_relu_or_gelu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmerged_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m x \u001b[38;5;241m=\u001b[39m src\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_first:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictAR(device, test_dataloader, model, SOS_TOKEN, EOS_TOKEN, id_course_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_DEPRECATED(device, model, dataloader):\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # iou_list = []\n",
    "\n",
    "    # Make predictions but don't calculate gradients on forward pass\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, X_pos, y, y_pos, X_pad_mask, y_pad_mask, majors, input_grades, target_grades) in enumerate(dataloader):\n",
    "            # # Fake y value for testing\n",
    "            # y_fake = y.clone()\n",
    "            # # Take all non-padded values and shift them by 1 (basically a random course)\n",
    "            # y_fake[y_fake != 0] = y_fake[y_fake != 0] + 1\n",
    "            # # Replace any values in y_fake that are greater than n_courses with n_courses - 1 to keep within the valid range\n",
    "            # y_fake[y_fake >= n_courses] = n_courses - 1\n",
    "            # # Put back the SOS token\n",
    "            # y_fake[:, 0] = y[:, 0]\n",
    "            # y_fake = y_fake.to(device)\n",
    "            # # Fake X value for testing\n",
    "            \n",
    "            # Place on device\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            X_pos = X_pos.to(device)\n",
    "            y_pos = y_pos.to(device)\n",
    "            X_pad_mask = X_pad_mask.to(device)\n",
    "            y_pad_mask = y_pad_mask.to(device)\n",
    "            majors = majors.to(device)\n",
    "            input_grades = input_grades.to(device)\n",
    "            target_grades = target_grades.to(device)\n",
    "\n",
    "            _, output_gpas, output_courses = model(major=majors,\n",
    "                                                    src_courses=X, \n",
    "                                                    tgt_courses=y, \n",
    "                                                    # tgt_courses=y_fake,\n",
    "                                                    src_gpas=input_grades, \n",
    "                                                    tgt_gpas=target_grades, \n",
    "                                                    src_courses_positions=X_pos, \n",
    "                                                    tgt_courses_positions=y_pos,\n",
    "                                                    src_courses_key_padding_mask=X_pad_mask,\n",
    "                                                    tgt_courses_key_padding_mask=y_pad_mask)\n",
    "\n",
    "        \n",
    "            # Get class predictions\n",
    "            pred_courses = output_courses.argmax(dim=1)\n",
    "\n",
    "            # print(f'output_courses[0].size(): {output_courses[0].size()}')\n",
    "            # print(f'output_courses[0]: {output_courses[0]}')\n",
    "            # print(f'pred_courses[0].size(): {pred_courses[0].size()}')\n",
    "            # print(f'pred_courses[0]: {pred_courses[0]}')\n",
    "\n",
    "            # Compute IOU for courses for the whole batch\n",
    "            mean_iou = mean_iou_batch(pred_courses, y, n_courses)\n",
    "\n",
    "            # # Convert predictions and acutal to sets\n",
    "            # pred_courses_set = set(pred_courses[0].unique().tolist())\n",
    "            # actual_courses_set = set(y[0].unique().tolist())\n",
    "\n",
    "            # # Remove padding values for metrics\n",
    "            # pred_courses_set = set([x for x in pred_courses_set if x != 0])\n",
    "            # actual_courses_set = set([x for x in actual_courses_set if x != 0])\n",
    "            \n",
    "            # Intersection over union\n",
    "            # iou = len(pred_courses_set.intersection(actual_courses_set)) / len(pred_courses_set.union(actual_courses_set))\n",
    "            # iou_list.append(iou)\n",
    "\n",
    "            # Get predicted grades\n",
    "            gpas_mask = y_pos != 0\n",
    "            # pred_gpas = output_gpas[gpas_mask]\n",
    "            # actual_gpas = target_grades[gpas_mask]\n",
    "\n",
    "            # Compute MAE\n",
    "            # mae = torch.mean(torch.abs(pred_gpas - actual_gpas))\n",
    "            # mae = masked_mae(output_gpas, target_grades, gpas_mask)   \n",
    "\n",
    "            # for i in range(len(X)):\n",
    "            #     # Convert predictions and acutal to sets\n",
    "            #     pred_courses_set = remove_duplicates(pred_courses[i].unique().tolist())\n",
    "            #     actual_courses_set = remove_duplicates(y[i].unique().tolist())\n",
    "            #     fake_courses_set = remove_duplicates(y_fake[i].unique().tolist())\n",
    "\n",
    "            #     # Remove padding values for metrics\n",
    "            #     pred_courses_set = remove_duplicates([x for x in pred_courses_set if x != 0])\n",
    "            #     actual_courses_set = remove_duplicates([x for x in actual_courses_set if x != 0])\n",
    "\n",
    "            #     # Get predicted and actual grades\n",
    "            #     # gpas_mask = y_pos != 0 # Ignore padded values (semesters)\n",
    "            #     # pred_gpas = output_gpas * gpas_mask # Get corresponding non-padded GPA predictions\n",
    "            #     # actual_gpas = target_grades * gpas_mask # Get actual non-padded GPAs\n",
    "\n",
    "            #     # Intersection over union\n",
    "            #     iou = len(set(pred_courses_set).intersection(set(actual_courses_set))) / len(set(pred_courses_set).union(set(actual_courses_set)))\n",
    "            #     iou_fake = len(set(pred_courses_set).intersection(set(fake_courses_set))) / len(set(pred_courses_set).union(set(fake_courses_set)))\n",
    "\n",
    "            #     # Get predicted grades\n",
    "            #     gpas_mask = y_pos != 0\n",
    "                \n",
    "            #     # pred_gpas = output_gpas[gpas_mask]\n",
    "            #     # actual_gpas = target_grades[gpas_mask]\n",
    "\n",
    "            #     # Compute MAE\n",
    "            #     # mae = torch.mean(torch.abs(pred_gpas - actual_gpas))\n",
    "            #     # mae = masked_mae(output_gpas, target_grades, gpas_mask, row_wise=True)\n",
    "\n",
    "            #     print(f'Major: {id_major_map[majors[i].item()]}')\n",
    "            #     print(f'Semester: {y_pos[i].unique()[1].item()}')\n",
    "            #     print(f'Prior semesters: {[id_course_map[x] for x in X[i].tolist() if x != 0]}')\n",
    "            #     print(f'Prior semester grades: {[np.round(4.3*x, 2) for x, i in zip(input_grades[i].tolist(), X[i].tolist()) if i != 0]}')\n",
    "            #     print(f'(Courses) Actual: {remove_duplicates([id_course_map[x.item()] for x in y[i] if x != 0])}')\n",
    "            #     print(f'(Courses) Fake: {remove_duplicates([id_course_map[x.item()] for x in y_fake[i] if x != 0])}')\n",
    "            #     print(f'(Courses) Predicted: {[id_course_map[x] for x in pred_courses_set]}')\n",
    "            #     # print(f'(Grades) Actual: {[np.round(4.3*x, 2) for x in actual_gpas.tolist() if x != 0]}')\n",
    "            #     # print(f'(Grades) Predicted: {[np.round(4.3*x, 2) for x in pred_gpas.tolist() if x != 0]}, MAE: {mae:.4f}')\n",
    "            #     print(f'IOU with real data: {iou:.1%}')\n",
    "            #     print(f'IOU with fake data: {iou_fake:.1%}')\n",
    "            #     # print(f'IOU%: {iou:.1%}, MAE: {mae[i]:.4f}')\n",
    "            #     print('-'*20)\n",
    "            # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([358], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314,\n",
      "        314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314,\n",
      "        314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314,\n",
      "        314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314,\n",
      "        314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314,\n",
      "        314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314,\n",
      "        314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314,\n",
      "        314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314,\n",
      "        314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314,\n",
      "        314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314,\n",
      "        314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314,\n",
      "        314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314,\n",
      "        314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314,\n",
      "        314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314,\n",
      "        314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314,\n",
      "        314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314,\n",
      "        314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314,\n",
      "        314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314,\n",
      "        314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "        314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314,\n",
      "        314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314,\n",
      "        314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314,\n",
      "        314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314,\n",
      "        314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "        314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314,\n",
      "        314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314,\n",
      "        314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314,\n",
      "        314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314,\n",
      "        314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "        314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314,\n",
      "        314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314,\n",
      "        314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314,\n",
      "        314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314,\n",
      "        314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314,\n",
      "        314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "        314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314,\n",
      "        314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314,\n",
      "        314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314,\n",
      "        314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314,\n",
      "        314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314,\n",
      "        314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "        314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314,\n",
      "        314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314,\n",
      "        314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314,\n",
      "        314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314,\n",
      "        314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314,\n",
      "        314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "        314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314, 314,\n",
      "        314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50, 314, 314, 314, 314, 314, 314, 314,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50,  50,  50,  50,  50, 314, 314, 314, 314, 314, 314, 314,  50,\n",
      "         50,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50, 314, 314, 314,\n",
      "        314, 314, 314, 314,  50,  50,  50,  50,  50,  50,  50,  50,  50,  50,\n",
      "         50,  50], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358,\n",
      "        314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358,\n",
      "        314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358,\n",
      "        314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,\n",
      "         77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358,\n",
      "        314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,\n",
      "         77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314,\n",
      "        358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358,\n",
      "        314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,\n",
      "         77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314,\n",
      "        358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358,\n",
      "        314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,\n",
      "         77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314,\n",
      "        358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,\n",
      "         76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358,\n",
      "        314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,\n",
      "         77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314,\n",
      "        358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,\n",
      "         76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "        314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358,\n",
      "        314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,\n",
      "         77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314,\n",
      "        358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,\n",
      "         76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "        314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358,\n",
      "        314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,\n",
      "         77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314,\n",
      "        358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,\n",
      "         76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "        314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,\n",
      "         84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358,\n",
      "        314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,\n",
      "         77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314,\n",
      "        358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,\n",
      "         76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "        314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,\n",
      "         84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358,\n",
      "        314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,\n",
      "         77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314,\n",
      "        358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,\n",
      "         76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "        314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,\n",
      "         84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,\n",
      "         77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358,\n",
      "        314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,\n",
      "         77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314,\n",
      "        358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,\n",
      "         76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "        314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,  24,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314, 333,\n",
      "         84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24, 314, 358, 314, 333,  84,  76,  77,  77,  24,  24,  24,  24,  24,\n",
      "         24,  24,  24,  24,  24,  24, 314, 358, 314, 333,  84,  76,  77,  77,\n",
      "         24,  24,  24,  24,  24,  24,  24,  24,  24,  24,  24, 314, 358, 314,\n",
      "        333,  84,  76,  77,  77,  24,  24,  24,  24,  24,  24,  24,  24,  24,\n",
      "         24,  24], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314,\n",
      "        314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314,\n",
      "        314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314,\n",
      "        314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314,\n",
      "        314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314,\n",
      "        314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314,\n",
      "        314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314,\n",
      "        314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314,\n",
      "        314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314,\n",
      "        314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317],\n",
      "       device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314,\n",
      "        314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314,\n",
      "        314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314,\n",
      "        314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314,\n",
      "        314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314,\n",
      "        314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314,\n",
      "        314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317], device='cuda:0')\n",
      "output_courses.size(): torch.Size([64, 359, 19])\n",
      "next_token.size(): torch.Size([64, 19])\n",
      "\n",
      "tensor([358, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314,\n",
      "        314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314,\n",
      "        314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237, 314,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 314,\n",
      "        314, 314, 314, 237, 314, 317, 317, 317, 317, 317, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 314, 314, 314, 314, 237, 314, 317, 317, 317, 317,\n",
      "        317, 317, 317, 317, 317, 317, 317, 317, 317, 314, 314, 314, 314, 237,\n",
      "        314, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317, 317],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[80], line 43\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(device, model, dataloader)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Perform a forward pass through the model\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tgt_seq[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 43\u001b[0m     _, output_gpas, output_courses \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmajor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmajors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43msrc_courses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtgt_courses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;66;43;03m# tgt_courses=y_fake,\u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43msrc_gpas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_grades\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtgt_gpas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_grades\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43msrc_courses_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtgt_courses_positions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43msrc_courses_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_pad_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtgt_courses_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_pad_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# Select the token with the highest probability at the last step\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_courses.size(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_courses\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\outcome_modeling\\models\\transformer.py:179\u001b[0m, in \u001b[0;36mTransformerModelWithGrades.forward\u001b[1;34m(self, major, src_courses, tgt_courses, src_gpas, tgt_gpas, src_courses_positions, tgt_courses_positions, src_courses_key_padding_mask, tgt_courses_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    176\u001b[0m tgt_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((tgt_mask, tgt_mask), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# Run through the transformer\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# Split the output into course and gpa outputs\u001b[39;00m\n\u001b[0;32m    187\u001b[0m output_courses, output_gpas \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplit(tgt_courses\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:206\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model \u001b[38;5;129;01mor\u001b[39;00m tgt\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model:\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 206\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(tgt, memory, tgt_mask\u001b[38;5;241m=\u001b[39mtgt_mask, memory_mask\u001b[38;5;241m=\u001b[39mmemory_mask,\n\u001b[0;32m    209\u001b[0m                       tgt_key_padding_mask\u001b[38;5;241m=\u001b[39mtgt_key_padding_mask,\n\u001b[0;32m    210\u001b[0m                       memory_key_padding_mask\u001b[38;5;241m=\u001b[39mmemory_key_padding_mask,\n\u001b[0;32m    211\u001b[0m                       tgt_is_causal\u001b[38;5;241m=\u001b[39mtgt_is_causal, memory_is_causal\u001b[38;5;241m=\u001b[39mmemory_is_causal)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:391\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    388\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 391\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[0;32m    394\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:685\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m why_not_sparsity_fast_path:\n\u001b[0;32m    684\u001b[0m         merged_mask, mask_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mmerge_masks(src_mask, src_key_padding_mask, src)\n\u001b[1;32m--> 685\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformer_encoder_layer_fwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m            \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_relu_or_gelu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmerged_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m x \u001b[38;5;241m=\u001b[39m src\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_first:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predict(device, model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom predictions\n",
    "\n",
    "Let the user \"create\" a student and then have the model predict courses and grades. This will allow us to play with different factors (e.g. course sequencing, different majors, etc) to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_semester = y_pos[0].max().item()\n",
    "\n",
    "# Grab just the first row for prediction\n",
    "pred_src_courses=X[0].unsqueeze(0).type(torch.long).to(device)\n",
    "pred_src_gpas=input_grades[0].unsqueeze(0).to(device)\n",
    "pred_src_courses_positions=X_pos[0].unsqueeze(0).type(torch.long).to(device)\n",
    "pred_src_courses_key_padding_mask=X_pad_mask[0].unsqueeze(0).type(torch.bool).to(device)\n",
    "pred_majors=majors[0].unsqueeze(0).type(torch.long).to(device)\n",
    "pred_memory_key_padding_mask=None\n",
    "\n",
    "# Actuals for comparison\n",
    "actual_tgt_courses=tgt_courses[0].unsqueeze(0).to(device)\n",
    "actual_tgt_gpas=tgt_gpas[0].unsqueeze(0).to(device)\n",
    "actual_tgt_courses_positions=tgt_courses_positions[0].unsqueeze(0).to(device)\n",
    "actual_tgt_courses_key_padding_mask=tgt_courses_key_padding_mask[0].unsqueeze(0).to(device)\n",
    "\n",
    "# # Create targets for prediction\n",
    "# pred_tgt_courses=torch.full((1, 1), actual_tgt_courses[0][0].item(), dtype=torch.long).to(device)\n",
    "# pred_tgt_gpas=torch.full((1, 1), actual_tgt_gpas[0][0].item(),dtype=torch.float).to(device)\n",
    "# pred_tgt_courses_positions=torch.full_like(pred_tgt_courses, fill_value=tgt_semester, dtype=torch.long).to(device)\n",
    "# pred_tgt_courses_key_padding_mask=torch.ones_like(pred_tgt_courses, dtype=torch.bool).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "major: 31\n",
      "\n",
      "src_courses:\n",
      " tensor([296, 341,  28,  96, 198,  31,  44,  17, 103,  73,  51, 256, 114,  23,\n",
      "         13,  72,  17, 259,  17, 126,   8, 297,  17, 260,  38,  52,  53,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0], device='cuda:0')\n",
      "\n",
      "src_gpas:\n",
      " tensor([0.8605, 0.9302, 0.7674, 0.9302, 0.9302, 0.9302, 1.0000, 1.0000, 0.8605,\n",
      "        0.6977, 0.4651, 0.9302, 0.9302, 0.9302, 0.9302, 0.9302, 0.9302, 0.9302,\n",
      "        0.9302, 0.9302, 0.0000, 0.9302, 0.9302, 0.9302, 0.9302, 0.6977, 0.7674,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000], device='cuda:0')\n",
      "\n",
      "src_courses_positions:\n",
      " tensor([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5,\n",
      "        5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "src_courses_key_padding_mask:\n",
      " tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "       device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'major: {pred_majors[0]}\\n')\n",
    "print(f'src_courses:\\n {pred_src_courses[0]}\\n')\n",
    "# print(f'tgt_courses:\\n {pred_tgt_courses[0]}\\n')\n",
    "print(f'src_gpas:\\n {pred_src_gpas[0]}\\n')\n",
    "# print(f'tgt_gpas:\\n {pred_tgt_gpas[0]}\\n')\n",
    "print(f'src_courses_positions:\\n {pred_src_courses_positions[0]}\\n')\n",
    "# print(f'tgt_courses_positions:\\n {pred_tgt_courses_positions[0]}\\n')\n",
    "print(f'src_courses_key_padding_mask:\\n {pred_src_courses_key_padding_mask[0]}\\n')\n",
    "# print(f'tgt_courses_key_padding_mask:\\n {pred_tgt_courses_key_padding_mask[0]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have the model make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_courses_lsm, output_gpas, output_courses = model(major=pred_majors,\n",
    "                                                            src_courses=pred_src_courses, \n",
    "                                                            # tgt_courses=pred_tgt_courses, \n",
    "                                                            tgt_courses=actual_tgt_courses,\n",
    "                                                            src_gpas=pred_src_gpas, \n",
    "                                                            # tgt_gpas=pred_tgt_gpas, \n",
    "                                                            tgt_gpas=actual_tgt_gpas,\n",
    "                                                            src_courses_positions=pred_src_courses_positions, \n",
    "                                                            # tgt_courses_positions=pred_tgt_courses_positions,\n",
    "                                                            tgt_courses_positions=actual_tgt_courses_positions,\n",
    "                                                            src_courses_key_padding_mask=pred_src_courses_key_padding_mask,\n",
    "                                                            tgt_courses_key_padding_mask=actual_tgt_courses_key_padding_mask\n",
    "                                                            # tgt_courses_key_padding_mask=pred_tgt_courses_key_padding_mask)\n",
    "    )\n",
    "    # Get class predictions\n",
    "    pred_courses = output_courses.topk(k=10, dim=1).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[314, 358, 358,  17,  36,  17, 314, 298, 298, 298, 298, 298, 298, 298,\n",
       "         298, 298, 298, 298, 298],\n",
       "        [237,  17,  17, 358,  51, 358, 330,  17,  17,  17,  17,  17,  17,  17,\n",
       "          17,  17,  17,  17,  17],\n",
       "        [148, 311, 311, 311, 314, 311,  51, 358, 358, 358, 358, 358, 358, 358,\n",
       "         358, 358, 358, 358, 358],\n",
       "        [320, 212, 212, 212, 300, 220, 148, 145, 145, 145, 145, 145, 145, 145,\n",
       "         145, 145, 145, 145, 145],\n",
       "        [ 51, 216, 267, 267, 148, 212,  76, 262, 262, 262, 262, 262, 262, 262,\n",
       "         262, 262, 262, 262, 262],\n",
       "        [330,  91,  91,  91, 330, 298, 320, 253, 253, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 253, 253],\n",
       "        [ 14, 267, 216, 220, 307,  91, 184, 177, 177, 177, 177, 177, 177, 177,\n",
       "         177, 177, 177, 177, 177],\n",
       "        [278, 200, 200, 216, 137, 160, 223, 100, 100, 100, 100, 100, 100, 100,\n",
       "         100, 100, 100, 100, 100],\n",
       "        [ 36, 220, 220, 200, 184, 216, 237, 274, 274, 274, 274, 274, 274, 274,\n",
       "         274, 274, 274, 274, 274],\n",
       "        [223, 149, 313, 313, 223, 177,  14, 212, 212, 212, 212, 212, 212, 212,\n",
       "         212, 212, 212, 212, 212]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_courses.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred_course_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43m[\u001b[49m\u001b[43mid_course_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred_courses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      2\u001b[0m actual_course_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([id_course_map[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m actual_tgt_courses\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mlist\u001b[39m(pred_course_set)\u001b[38;5;241m.\u001b[39msort()\n",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred_course_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([\u001b[43mid_course_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m pred_courses\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mtolist()])\n\u001b[0;32m      2\u001b[0m actual_course_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([id_course_map[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m actual_tgt_courses\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mlist\u001b[39m(pred_course_set)\u001b[38;5;241m.\u001b[39msort()\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "pred_course_set = set([id_course_map[x] for x in pred_courses.squeeze().tolist()])\n",
    "actual_course_set = set([id_course_map[x] for x in actual_tgt_courses.squeeze().tolist() if x != 0])\n",
    "\n",
    "list(pred_course_set).sort()\n",
    "list(actual_course_set).sort()\n",
    "\n",
    "print(f'Actual: {actual_course_set}\\nPredicted: {pred_course_set}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BIOL 2334', 'CHEM 2123', 'CHEM 2323', 'MATH 2413', 'WRIT 2302'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([id_course_map[x] for x in actual_tgt_courses.squeeze().tolist() if x != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30b7ed66ca140c497c9169acc625f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Major:', options={'Behavioral Neuroscience': 1, 'Business Administration'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "major_selector = widgets.Dropdown(\n",
    "    options=major_id_map,\n",
    "    value=1,\n",
    "    description='Major:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Create a label which shows the selected value from the dropdown\n",
    "output = widgets.Label(value=f'Selected major ID: {major_selector.value}')\n",
    "\n",
    "def update_label(change):\n",
    "    output.value = f'Selected major ID: {str(change.new)}'\n",
    "\n",
    "major_selector.observe(update_label, names='value')\n",
    "\n",
    "# Link the value of the dropdown to the label\n",
    "display(widgets.HBox([major_selector, output]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty (zero) tensors for sources to simulate the first semester\n",
    "pred_empty_src_courses = torch.zeros_like(X, dtype=torch.long)[0].unsqueeze(0).to(device)\n",
    "pred_empty_src_gpas = torch.zeros_like(input_grades, dtype=torch.float)[0].unsqueeze(0).to(device)\n",
    "pred_empty_src_courses_positions = torch.zeros_like(X_pos, dtype=torch.long)[0].unsqueeze(0).to(device)\n",
    "pred_empty_src_courses_key_padding_mask = torch.zeros_like(X_pad_mask, dtype=torch.bool)[0].unsqueeze(0).to(device)\n",
    "pred_empty_majors = torch.LongTensor([major_selector.value]).to(device)\n",
    "\n",
    "# Create empty (zero) tensors for targets to simulate the first semester\n",
    "pred_empty_tgt_courses = torch.zeros((1, 1), dtype=torch.long).to(device)\n",
    "pred_empty_tgt_gpas = torch.zeros((1, 1), dtype=torch.float).to(device)\n",
    "pred_empty_tgt_courses_positions = torch.ones((1, 1), dtype=torch.long).to(device)\n",
    "pred_empty_tgt_courses_key_padding_mask = torch.ones((1, 1), dtype=torch.bool).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check to make sure everything looks good (besides major and indicator for first semester, it should all be zeros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_courses:\n",
      " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "\n",
      "tgt_courses:\n",
      " tensor([[0]], device='cuda:0')\n",
      "\n",
      "src_gpas:\n",
      " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "\n",
      "tgt_gpas:\n",
      " tensor([[0.]], device='cuda:0')\n",
      "\n",
      "major: tensor([1], device='cuda:0')\n",
      "\n",
      "src_courses_positions:\n",
      " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')\n",
      "\n",
      "tgt_courses_positions:\n",
      " tensor([[1]], device='cuda:0')\n",
      "\n",
      "src_courses_key_padding_mask:\n",
      " tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "\n",
      "tgt_courses_key_padding_mask:\n",
      " tensor([[True]], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'src_courses:\\n {pred_empty_src_courses}\\n')\n",
    "print(f'tgt_courses:\\n {pred_empty_tgt_courses}\\n')\n",
    "print(f'src_gpas:\\n {pred_empty_src_gpas}\\n')\n",
    "print(f'tgt_gpas:\\n {pred_empty_tgt_gpas}\\n')\n",
    "print(f'major: {pred_empty_majors}\\n')\n",
    "print(f'src_courses_positions:\\n {pred_empty_src_courses_positions}\\n')\n",
    "print(f'tgt_courses_positions:\\n {pred_empty_tgt_courses_positions}\\n')\n",
    "print(f'src_courses_key_padding_mask:\\n {pred_empty_src_courses_key_padding_mask}\\n')\n",
    "print(f'tgt_courses_key_padding_mask:\\n {pred_empty_tgt_courses_key_padding_mask}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "output_courses_lsm, output_gpas, output_courses = model(major=pred_empty_majors,\n",
    "                                                        src_courses=pred_empty_src_courses, \n",
    "                                                        tgt_courses=pred_empty_tgt_courses, \n",
    "                                                        src_gpas=pred_empty_src_gpas, \n",
    "                                                        tgt_gpas=pred_empty_tgt_gpas, \n",
    "                                                        src_courses_positions=pred_empty_src_courses_positions, \n",
    "                                                        tgt_courses_positions=pred_empty_tgt_courses_positions,\n",
    "                                                        src_courses_key_padding_mask=pred_empty_src_courses_key_padding_mask,\n",
    "                                                        tgt_courses_key_padding_mask=pred_empty_tgt_courses_key_padding_mask)\n",
    "# Get class predictions\n",
    "pred_course = output_courses.topk(k=10, dim=1).indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>',\n",
       " 'BIOL 2334',\n",
       " 'PSYC 2310',\n",
       " 'PSYC 2317',\n",
       " 'PSYC 2321',\n",
       " 'PSYC 3319',\n",
       " 'PSYC 3352',\n",
       " 'PSYC 3438',\n",
       " 'PSYC 4341',\n",
       " 'WRIT 2302'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([id_course_map[x] for x in pred_course.squeeze().tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major embeddings\n",
    "Understand if the major embeddings are capturing anything meaningful (or even being used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    # Majors\n",
    "    major_idxs = np.arange(n_majors)\n",
    "    major_tensor = torch.tensor(major_idxs).to(device)\n",
    "    major_embeddings = model.major_embedding(major_tensor).squeeze()\n",
    "\n",
    "    # Courses\n",
    "    course_idxs = np.arange(n_courses)\n",
    "    course_tensor = torch.tensor(course_idxs).to(device)\n",
    "    course_embeddings = model.course_embedding(course_tensor).squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_closest(tensor, row_index, k):\n",
    "    \"\"\"\n",
    "    Find the K closest rows in `tensor` to the row at `row_index` using cosine similarity.\n",
    "\n",
    "    Args:\n",
    "    - tensor (torch.Tensor): Input tensor of shape [batch size, embedding size].\n",
    "    - row_index (int): Index of the row to compare against.\n",
    "    - k (int): Number of closest rows to find.\n",
    "\n",
    "    Returns:\n",
    "    - indices (torch.Tensor): Indices of the K closest rows.\n",
    "    \"\"\"\n",
    "    # Compute cosine similarities\n",
    "    normalized_tensor = F.normalize(tensor, p=2, dim=1)\n",
    "    cosine_similarities = torch.matmul(normalized_tensor, normalized_tensor[row_index].unsqueeze(1)).squeeze()\n",
    "\n",
    "    # Set the similarity of the row with itself to -1 to exclude it from being one of the closest\n",
    "    cosine_similarities[row_index] = -1\n",
    "\n",
    "    # Find the indices of the K largest similarities (which are the closest)\n",
    "    _, indices = torch.topk(cosine_similarities, k, largest=True)\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_farthest(tensor, row_index, k):\n",
    "    \"\"\"\n",
    "    Find the K farthest rows in `tensor` to the row at `row_index` using cosine similarity.\n",
    "\n",
    "    Args:\n",
    "    - tensor (torch.Tensor): Input tensor of shape [batch size, embedding size].\n",
    "    - row_index (int): Index of the row to compare against.\n",
    "    - k (int): Number of farthest rows to find.\n",
    "\n",
    "    Returns:\n",
    "    - indices (torch.Tensor): Indices of the K farthest rows.\n",
    "    \"\"\"\n",
    "    # Compute cosine similarities\n",
    "    normalized_tensor = F.normalize(tensor, p=2, dim=1)\n",
    "    cosine_similarities = torch.matmul(normalized_tensor, normalized_tensor[row_index].unsqueeze(1)).squeeze()\n",
    "\n",
    "    # Set the similarity of the row with itself to 1 to exclude it from being one of the farthest\n",
    "    cosine_similarities[row_index] = 1\n",
    "\n",
    "    # Find the indices of the K smallest similarities (which are the farthest)\n",
    "    _, indices = torch.topk(cosine_similarities, k, largest=False)\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_neighbors(embeddings, name, id_name_map, name_id_map, k=5):\n",
    "    nbrs = find_k_closest(embeddings, name_id_map[name], k=k)\n",
    "\n",
    "    return [id_name_map[x.item()] for x in nbrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_farthest_neighbors(embeddings, name, id_name_map, name_id_map, k=5):\n",
    "    nbrs = find_k_farthest(embeddings, name_id_map[name], k=k)\n",
    "    return [id_name_map[x.item()] for x in nbrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_major = 'Biology'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer Info Science',\n",
       " 'Communication',\n",
       " 'Writing and Rhetoric',\n",
       " 'Chemistry',\n",
       " 'Political Science',\n",
       " 'Interdisciplinary Studies',\n",
       " 'Behavioral Neuroscience',\n",
       " 'Art',\n",
       " 'Management',\n",
       " 'International Business']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_neighbors(major_embeddings, test_major, id_major_map, major_id_map, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer Science',\n",
       " 'History',\n",
       " 'Theater Arts',\n",
       " 'Philosophy',\n",
       " 'Global Studies',\n",
       " 'Entrepreneurship',\n",
       " 'Graphic Design',\n",
       " 'Academic Exploration-ND',\n",
       " 'Forensic Science',\n",
       " 'Forensic Science, Laboratory']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_farthest_neighbors(major_embeddings, test_major, id_major_map, major_id_map, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POLS 2341',\n",
       " 'PSYC 2301',\n",
       " 'CRIJ 2306',\n",
       " 'BIOL 2113',\n",
       " 'KINE 1129',\n",
       " 'ACCT 2301',\n",
       " 'COSC 2331',\n",
       " 'VGAM 1303',\n",
       " 'CRIJ 1310',\n",
       " 'ASTR 1311']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_course = 'MATH 2413'\n",
    "find_neighbors(course_embeddings, test_course, id_course_map, course_id_map, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GEOG 1303',\n",
       " 'MATH 309',\n",
       " 'ENGL 2324',\n",
       " 'FSEM 1409',\n",
       " 'COSC 2425',\n",
       " 'FSEM 1407',\n",
       " 'RELS 1315',\n",
       " 'KINE 2335',\n",
       " 'COSC 2325',\n",
       " 'PHYS 2425']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_farthest_neighbors(course_embeddings, test_course, id_course_map, course_id_map, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients for the self-attention layer weights in the first encoder layer:\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 3 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Make a dual bar plot of the max and min gradients for each parameter\u001b[39;00m\n\u001b[0;32m     22\u001b[0m grad_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(grad_dict)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m---> 23\u001b[0m \u001b[43mgrad_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL2 norm\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     24\u001b[0m grad_df \u001b[38;5;241m=\u001b[39m grad_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m grad_df_zero \u001b[38;5;241m=\u001b[39m grad_df[grad_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-8\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:6310\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6308\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6309\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6311\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6312\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:813\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    812\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 813\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_set_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\Users\\pauls\\Projects\\NSCI-retention-modeling\\venv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 3 elements"
     ]
    }
   ],
   "source": [
    "# Zero the gradients first\n",
    "model.zero_grad()\n",
    "\n",
    "# Example forward pass (replace with your actual input data)\n",
    "output_courses_lsm, output_gpas, output_courses = model(major=majors,\n",
    "                                                        src_courses=X, \n",
    "                                                        tgt_courses=y, \n",
    "                                                        src_gpas=input_grades, \n",
    "                                                        tgt_gpas=target_grades, \n",
    "                                                        src_courses_positions=X_pos, \n",
    "                                                        tgt_courses_positions=y_pos,\n",
    "                                                        src_courses_key_padding_mask=X_pad_mask,\n",
    "                                                        tgt_courses_key_padding_mask=y_pad_mask)\n",
    "\n",
    "# Compute the loss (replace with your actual loss function)\n",
    "# Course prediction loss function\n",
    "# Summing along dimension 1 creates a vector which has a 1 for each\n",
    "# course they actually took. Padding will be counted multiple times to\n",
    "# encourage the model to not over-predict courses.\n",
    "y_oh = F.one_hot(y, num_classes=n_courses).sum(dim=1)\n",
    "y_oh = torch.clamp(y_oh, 0, 1)\n",
    "y_norm = y_oh / y_oh.sum(dim=1, keepdim=True)\n",
    "\n",
    "# Mask the padding values when computing loss\n",
    "course_loss = course_loss_fn(output_courses_lsm, y_norm)\n",
    "mask = torch.ones_like(y_oh)\n",
    "mask[:, 0] = 0\n",
    "masked_loss = course_loss * mask\n",
    "course_reduced_loss = masked_loss.sum() / mask.sum()\n",
    "\n",
    "# GPA loss function\n",
    "# Mask the padding values when computing loss\n",
    "gpa_loss = gpa_loss_fn(output_gpas.squeeze(), target_grades.squeeze())\n",
    "mask = torch.ones_like(target_grades)\n",
    "mask[y_pos == 0] = 0\n",
    "masked_loss = gpa_loss * mask\n",
    "gpa_reduced_loss = masked_loss.sum() / mask.sum()\n",
    "\n",
    "loss = course_loss_weight*course_reduced_loss + gpa_reduced_loss\n",
    "\n",
    "# Backward pass to compute gradients\n",
    "loss.backward()\n",
    "\n",
    "# Inspect gradients of a specific parameter or layer\n",
    "print(\"Gradients for the self-attention layer weights in the first encoder layer:\")\n",
    "print(model.transformer.encoder.layers[0].self_attn.in_proj_weight.grad)\n",
    "\n",
    "grad_dict = dict()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None and '.bias' not in name:\n",
    "        grad_dict[name] = [param.grad.abs().max().item(), param.grad.abs().min().item(), param.grad.data.norm(p=2).item()]\n",
    "        # print(f\"Gradients for {name}:\")\n",
    "        # print(f'Max: {param.grad.abs().max()}')\n",
    "        # print(f'Min: {param.grad.abs().min()}\\n')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Make a dual bar plot of the max and min gradients for each parameter\n",
    "grad_df = pd.DataFrame(grad_dict).T\n",
    "grad_df.columns = ['Max', 'Min', 'L2 norm']\n",
    "grad_df = grad_df.sort_values(by='Max', ascending=False)\n",
    "grad_df_zero = grad_df[grad_df['Max'] <= 1e-8]\n",
    "grad_df = grad_df[grad_df['Max'] > 1e-8]\n",
    "grad_df['Max_log'] = np.log(grad_df['Max'])\n",
    "grad_df['L2 norm log'] = np.log(grad_df['L2 norm'])\n",
    "\n",
    "# Plot the dual bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 40))\n",
    "grad_df['L2 norm log'].plot(kind='barh', ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Max, Min]\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_df_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
